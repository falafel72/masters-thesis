@InProceedings{Agrawal2012,
  author    = {Amit Agrawal and Srikumar Ramalingam and Yuichi Taguchi and Visesh Chari},
  booktitle = {2012 {IEEE} Conference on Computer Vision and Pattern Recognition},
  title     = {A theory of multi-layer flat refractive geometry},
  year      = {2012},
  month     = {jun},
  publisher = {{IEEE}},
  doi       = {10.1109/cvpr.2012.6248073},
  groups    = {Optics},
}

@Article{AkshitaSaini2019,
  author  = {Akshita Saini, Mantosh Biswas},
  journal = {ICOEI},
  title   = {Object Detection in Underwater Image by DetectingEdges using Adaptive Thresholding},
  year    = {2019},
  groups  = {Image Processing, Fish Analysis},
}

@Article{Amitai2022,
  author        = {Amitai, Shlomi and Klein, Itzik and Treibitz, Tali},
  title         = {Self-Supervised Monocular Depth Underwater},
  year          = {2022},
  month         = oct,
  abstract      = {Depth estimation is critical for any robotic system. In the past years estimation of depth from monocular images have shown great improvement, however, in the underwater environment results are still lagging behind due to appearance changes caused by the medium. So far little effort has been invested on overcoming this. Moreover, underwater, there are more limitations for using high resolution depth sensors, this makes generating ground truth for learning methods another enormous obstacle. So far unsupervised methods that tried to solve this have achieved very limited success as they relied on domain transfer from dataset in air. We suggest training using subsequent frames self-supervised by a reprojection loss, as was demonstrated successfully above water. We suggest several additions to the self-supervised framework to cope with the underwater environment and achieve state-of-the-art results on a challenging forward-looking underwater dataset.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
  doi           = {10.48550/ARXIV.2210.03206},
  eprint        = {2210.03206},
  file          = {:http\://arxiv.org/pdf/2210.03206v1:PDF},
  groups        = {Monocular Depth Camera},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), Robotics (cs.RO), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  publisher     = {arXiv},
}

@Article{Baba2001,
  author    = {Mitsuru Baba and Kozo Ohtani and Makoto Imai and Tadataka Konishi},
  journal   = {Optical Engineering},
  title     = {{New laser rangefinder for three-dimensional shape measurement of specular objects}},
  year      = {2001},
  number    = {1},
  pages     = {53 -- 60},
  volume    = {40},
  doi       = {10.1117/1.1331269},
  groups    = {Laser Rangefinder},
  keywords  = {Image sensors, Photomasks, Reflectivity, Charge-coupled devices, Commercial off the shelf technology, Metals, Optical engineering, 3D metrology, Projection systems, Prototyping},
  publisher = {SPIE},
  url       = {https://doi.org/10.1117/1.1331269},
}

@Article{Barreto2013,
  author  = {Saulo Vinicius Ferreira Barreto and Remy Eskinazi Sant'Anna and Marc{\'i}lio Andr{\'e} F{\'e}lix Feitosa},
  journal = {2013 IEEE 20th International Conference on Electronics, Circuits, and Systems (ICECS)},
  title   = {A method for image processing and distance measuring based on laser distance triangulation},
  year    = {2013},
  pages   = {695-698},
  groups  = {Laser Rangefinder},
  url     = {https://api.semanticscholar.org/CorpusID:17466529},
}

@Article{Bell1985,
  author    = {Bell, JD and Craik, GJS and Pollard, DA and Russell, BC},
  journal   = {Coral Reefs},
  title     = {Estimating length frequency distributions of large reef fish underwater},
  year      = {1985},
  pages     = {41--44},
  volume    = {4},
  doi       = {https://doi.org/10.1007/BF00302203},
  groups    = {Fish Analysis},
  publisher = {Springer},
}

@Article{BERGERON2007,
  author    = {PATRICK BERGERON},
  journal   = {Journal of Wildlife Management},
  title     = {Parallel Lasers for Remote Measurements of Morphological Traits},
  year      = {2007},
  month     = {feb},
  number    = {1},
  pages     = {289--292},
  volume    = {71},
  doi       = {10.2193/2006-290},
  groups    = {Laser Rangefinder},
  publisher = {Wiley},
}

@Article{Boudhane2016,
  author    = {Mohcine Boudhane and Benayad Nsiri},
  journal   = {Journal of Visual Communication and Image Representation},
  title     = {Underwater image processing method for fish localization and detection in submarine environment},
  year      = {2016},
  month     = {aug},
  pages     = {226--238},
  volume    = {39},
  doi       = {10.1016/j.jvcir.2016.05.017},
  groups    = {Fish Analysis},
  publisher = {Elsevier {BV}},
}

@Article{Breuer2007,
  author   = {Breuer, Thomas and Robbins, Martha M. and Boesch, Christophe},
  journal  = {American Journal of Physical Anthropology},
  title    = {Using photogrammetry and color scoring to assess sexual dimorphism in wild western gorillas (Gorilla gorilla)},
  year     = {2007},
  number   = {3},
  pages    = {369-382},
  volume   = {134},
  abstract = {Abstract Investigating sexual dimorphism is important for our understanding of its influence on reproductive strategies including maleâmale competition, mate choice, and sexual conflict. Measuring physical traits in wild animals can be logistically challenging and disruptive for the animals. Therefore body size and ornament variation in wild primates have rarely been quantified. Gorillas are amongst the most sexually dimorphic and dichromatic primates. Adult males (silverbacks) possess a prominent sagittal crest, a pad of fibrous and fatty tissue on top of the head, have red crest coloration, their saddle appears silver, and they possess a silverline along their stomach. Here we measure levels of sexual dimorphism and within-male variation of body length, head size, and sexual dichromatism in a population of wild western gorillas using photogrammetry. Digital photogrammetry is a useful and precise method to measure sexual dimorphism in physical traits yielding sexual dimorphism indices (ISD), similar to those derived from traditional measurements of skeletal remains. Silverbacks were on an average 1.23 times longer in body length than adult females. Sexual dimorphism of head size was highest in measures of crest size (max ISD: 60.4) compared with measures of facial height (max ISD: 24.7). The most sexually dimorphic head size measures also showed the highest within-sex variation. We found no clear sex differences in crest coloration but there was large sexual dichromatism with high within-male variation in saddle coloration and silverline size. Further studies should examine if these sexually dimorphic traits are honest signals of competitive ability and confer an advantage in reproductive success. Am J Phys Anthropol, 2007. Â© 2007 Wiley-Liss, Inc.},
  doi      = {https://doi.org/10.1002/ajpa.20678},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ajpa.20678},
  groups   = {Laser Rangefinder},
  keywords = {coloration, body length, photogrammetry, sagittal crest, sexual selection},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ajpa.20678},
}

@Article{Buchsbaum1980,
  author   = {G. Buchsbaum},
  journal  = {Journal of the Franklin Institute},
  title    = {A spatial processor model for object colour perception},
  year     = {1980},
  issn     = {0016-0032},
  number   = {1},
  pages    = {1-26},
  volume   = {310},
  abstract = {A comprehensive mathematical model to account for colour constancy is formulated. Since the visual system is able to measure true object colour in complex scenes under a broad range of spectral compositions, for the illumination; it is assumed that the visual system must implicitly estimate and illuminant. The basic hypothesis is that the estimate of the illuminant is made on the basis of spatial information from the entire visual field. This estimate is then used by the visual system to arrive at an estimate of the (object) reflectance of the various subfields in the complex visual scene. The estimates are made by matching the inputs to the system to linear combinations of fixed bases and standards in the colour space. The model provides a general unified mathematical framework for related psychophysical phenomenology.},
  doi      = {https://doi.org/10.1016/0016-0032(80)90058-7},
  groups   = {Image Processing},
  url      = {https://www.sciencedirect.com/science/article/pii/0016003280900587},
}

@Article{Caldwell2016,
  author    = {Caldwell, Zachary R. AND Zgliczynski, Brian J. AND Williams, Gareth J. AND Sandin, Stuart A.},
  journal   = {PLOS ONE},
  title     = {Reef Fish Survey Techniques: Assessing the Potential for Standardizing Methodologies},
  year      = {2016},
  month     = {04},
  number    = {4},
  pages     = {1-14},
  volume    = {11},
  abstract  = {Dramatic changes in populations of fishes living on coral reefs have been documented globally and, in response, the research community has initiated efforts to assess and monitor reef fish assemblages. A variety of visual census techniques are employed, however results are often incomparable due to differential methodological performance. Although comparability of data may promote improved assessment of fish populations, and thus management of often critically important nearshore fisheries, to date no standardized and agreed-upon survey method has emerged. This study describes the use of methods across the research community and identifies potential drivers of method selection. An online survey was distributed to researchers from academic, governmental, and non-governmental organizations internationally. Although many methods were identified, 89% of survey-based projects employed one of three methods - belt transect, stationary point count, and some variation of the timed swim method. The selection of survey method was independent of the research design (i.e., assessment goal) and region of study, but was related to the researchers home institution. While some researchers expressed willingness to modify their current survey protocols to more standardized protocols (76%), their willingness decreased when methodologies were tied to long-term datasets spanning five or more years. Willingness to modify current methodologies was also less common among academic researchers than resource managers. By understanding both the current application of methods and the reported motivations for method selection, we hope to focus discussions towards increasing the comparability of quantitative reef fish survey data.},
  doi       = {10.1371/journal.pone.0153066},
  groups    = {Fish Analysis},
  publisher = {Public Library of Science},
  url       = {https://doi.org/10.1371/journal.pone.0153066},
}

@Article{Cavan2021,
  author    = {Emma L. Cavan and Simeon L. Hill},
  journal   = {Global Change Biology},
  title     = {Commercial fishery disturbance of the global ocean biological carbon sink},
  year      = {2021},
  month     = {dec},
  number    = {4},
  pages     = {1212--1221},
  volume    = {28},
  doi       = {10.1111/gcb.16019},
  groups    = {Ecology},
  publisher = {Wiley},
}

@Article{Cavedo2016,
  author  = {Cavedo, Federico and Norgia, Michele and Pesatori, Alessandro and Solari, Gabriel E.},
  journal = {IEEE Transactions on Instrumentation and Measurement},
  title   = {Steel Pipe Measurement System Based on Laser Rangefinder},
  year    = {2016},
  number  = {6},
  pages   = {1472-1477},
  volume  = {65},
  doi     = {10.1109/TIM.2016.2514758},
  groups  = {Laser Rangefinder},
}

@Article{Churnside2012,
  author = {es Churnside, Jam and Jech, Michael and Tenningen, Eirik and McElderry, Howard and O'Driscoll, Richard and Ryan, Tim E and Shortis, Mark R and Smith, Stephen J and aldo Wakefield, WW},
  title  = {Fishery applications of optical technologies},
  year   = {2012},
  groups = {Stereo Camera},
  url    = {https://www.vliz.be/imisdocs/publications/ocrd/236653.pdf},
}

@Article{Cisar2021,
  author    = {Petr Cisar and Dinara Bekkozhayeva and Oleksandr Movchan and Mohammadmehdi Saberioon and Rudolf Schraml},
  journal   = {Scientific Reports},
  title     = {Computer vision based individual fish identification using skin dot pattern},
  year      = {2021},
  month     = {aug},
  number    = {1},
  volume    = {11},
  doi       = {10.1038/s41598-021-96476-4},
  file      = {:https\://www.nature.com/articles/s41598-021-96476-4.pdf:PDF},
  groups    = {Fish Analysis},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{COOKE2007,
  author    = {S. J. COOKE and H. L. SCHRAMM},
  journal   = {Fisheries Management and Ecology},
  title     = {Catch-and-release science and its application to conservation and management of recreational fisheries},
  year      = {2007},
  month     = {apr},
  number    = {2},
  pages     = {73--79},
  volume    = {14},
  doi       = {10.1111/j.1365-2400.2007.00527.x},
  groups    = {Ecology},
  publisher = {Wiley},
}

@Software{Crutchfield_FishSense-Lite,
  author  = {Crutchfield, Christopher L. and Hu, Kyle S. and Suresh, Vivaswat and Grant, Hamish J. and Perez, Ana I.},
  license = {BSD-3-Clause},
  title   = {{FishSense-Lite}},
  url     = {https://github.com/UCSD-E4E/fishsense-lite},
}

@InProceedings{Dawkins2017,
  author    = {Matthew Dawkins and Linus Sherrill and Keith Fieldhouse and Anthony Hoogs and Benjamin Richards and David Zhang and Lakshman Prasad and Kresimir Williams and Nathan Lauffenburger and Gaoang Wang},
  booktitle = {2017 {IEEE} Winter Conference on Applications of Computer Vision ({WACV})},
  title     = {An Open-Source Platform for Underwater Image and Video Analytics},
  year      = {2017},
  month     = {mar},
  publisher = {{IEEE}},
  doi       = {10.1109/wacv.2017.105},
  groups    = {Fish Analysis},
}

@Article{Duda1979,
  author    = {Richard O. Duda and David Nitzan and Phyllis Barrett},
  journal   = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
  title     = {Use of Range and Reflectance Data to Find Planar Surface Regions},
  year      = {1979},
  month     = {jul},
  number    = {3},
  pages     = {259--271},
  volume    = {{PAMI}-1},
  doi       = {10.1109/tpami.1979.4766922},
  groups    = {Laser Rangefinder},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Dyck2010,
  author    = {Andrew J. Dyck and U. Rashid Sumaila},
  journal   = {Journal of Bioeconomics},
  title     = {Economic impact of ocean fish populations in the global fishery},
  year      = {2010},
  month     = {aug},
  number    = {3},
  pages     = {227--243},
  volume    = {12},
  doi       = {10.1007/s10818-010-9088-3},
  groups    = {Ecology},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Ebrahim2015,
  author  = {Ebrahim, Mostafa Abdel-Bary},
  journal = {Int J Sci Res},
  title   = {3D laser scanners’ techniques overview},
  year    = {2015},
  number  = {10},
  pages   = {323--331},
  volume  = {4},
  groups  = {Laser Rangefinder},
}

@Article{Falkenberg2020,
  author    = {Laura J. Falkenberg and Richard G.J. Bellerby and Sean D. Connell and Lora E. Fleming and Bruce Maycock and Bayden D. Russell and Francis J. Sullivan and Sam Dupont},
  journal   = {International Journal of Environmental Research and Public Health},
  title     = {Ocean Acidification and Human Health},
  year      = {2020},
  month     = {jun},
  number    = {12},
  pages     = {4563},
  volume    = {17},
  doi       = {10.3390/ijerph17124563},
  groups    = {Ecology},
  publisher = {{MDPI} {AG}},
}

@Article{Feely2001,
  author    = {Feely, Richard A and Sabine, Christopher L and Takahashi, Taro and Wanninkhof, Rik and others},
  journal   = {OCEANOGRAPHY-WASHINGTON DC-OCEANOGRAPHY SOCIETY-},
  title     = {Uptake and storage of carbon dioxide in the ocean: The global co2 survey},
  year      = {2001},
  number    = {4},
  pages     = {18--32},
  volume    = {14},
  groups    = {Ecology},
  publisher = {The Oceanographic Society; 1999},
  url       = {https://pdfs.semanticscholar.org/d54b/bb1529943644f11467177be81b93fa30f8d8.pdf},
}

@Online{Fishial2023,
  author       = {Fishial},
  groups       = {Fish Analysis},
  organization = {Fishial.AI},
  title        = {Home | Fishial},
  url          = {https://fishial.ai/},
  year         = {2023},
}

@Article{Forrest2023,
  author   = {Forrest, Matthew J. and Favoretto, Fabio and Nisa, Zahidah A. and Aburto-Oropeza, Octavio},
  journal  = {Frontiers in Marine Science},
  title    = {A deeper dive into the blue economy: the role of the diving sector in conservation and sustainable development goals},
  year     = {2023},
  issn     = {2296-7745},
  volume   = {10},
  abstract = {Attaining an equitable Blue Economy requires reconsidering historical extractive usages of natural ocean capital in favor of more sustainable activities. Scuba diving is an expanding industry, and several examples illustrate how the diving sector has assisted with transitions to sustainable economic activities. In certain countries diving tourism generates revenues comparable with fishing industries, yet the sector remains underrepresented within marine conservation efforts. Therefore, we present five actions tailored to enhance the diving sector’s participation in the Blue Economy: i) Organize the fragmented sector via international associations and federations; ii) Recognize usage rights for natural capital equal to extractive activities; iii) Modernize the sector using technology to improve connectivity and data sharing; iv) Invest in the sector by engaging private and public funding and subsidizing critical infrastructure to enable equitable access; v) Foster a sense of community by training and supporting local leaders, thereby ensuring more equitable participation by including women, indigenous people, and the youth. Diving represents one of the only endeavors that enables citizens to actively support the Blue Economy and help to achieve the United Nations Sustainable Development Goal 14, “Life Below Water”; therefore, the diving sector is uniquely poised to help address conservation goals and sustainable development.},
  doi      = {10.3389/fmars.2023.1212790},
  groups   = {Ecology},
  url      = {https://www.frontiersin.org/articles/10.3389/fmars.2023.1212790},
}

@Article{Fu2014,
  author  = {Fu, Xueyang and Zhuang, Peixian and Huang, Yue and Liao, Yinghao and Zhang, Xiao-Ping and Ding, Xinghao},
  journal = {2014 IEEE International Conference on Image Processing (ICIP)},
  title   = {A retinex-based enhancing approach for single underwater image},
  year    = {2014},
  groups  = {Image Processing, Fish Analysis},
}

@Article{Gaygusuz2006,
  author    = {Gaygusuz, {\" O}zcan and G{\" u}rsoy, {\c C}i{\u g}dem and {\" O}zulu{\u g}, M{\" u}fit and Tarkan, Ali Serhan and Ac{\i}p{\i}nar, Hasan and Bilge, G{\" o}k{\c c}en and Filiz, Halit},
  journal   = {Turkish Journal of Fisheriez and Aquatic Sciences},
  title     = {Conversions of Total, Fork and Standard Length Measurements Based on 42 Marine and Freshwater Fish Species (from Turkish Waters)},
  year      = {2006},
  issn      = {1303-2712},
  number    = {2},
  pages     = {-},
  volume    = {6},
  groups    = {Fish Analysis},
  key       = {cite},
  publisher = {Trabzon Su {\" U}r{\" u}nleri Merkez Ara{\c s}t{\i}rma Enstit{\" u}s{\" u}},
}

@InProceedings{Gedge2011,
  author    = {Jason Gedge and Minglun Gong and Yee-Hong Yang},
  booktitle = {2011 Canadian Conference on Computer and Robot Vision},
  title     = {Refractive Epipolar Geometry for Underwater Stereo Matching},
  year      = {2011},
  month     = {may},
  publisher = {{IEEE}},
  doi       = {10.1109/crv.2011.26},
  groups    = {Stereo Camera, Optics},
}

@Article{Goetze2019,
  author   = {Goetze, Jordan S. and Bond, Todd. and McLean, Dianne L. and Saunders, Benjamin J. and Langlois, Tim J. and Lindfield, Steve and Fullwood, Laura. A. F. and Driessen, Damon and Shedrawi, George and Harvey, Euan S.},
  journal  = {Methods in Ecology and Evolution},
  title    = {A field and video analysis guide for diver operated stereo-video},
  year     = {2019},
  number   = {7},
  pages    = {1083-1090},
  volume   = {10},
  abstract = {Abstract There has been rapid uptake of stereo-video-based sampling techniques to collect species, abundance and body-size information on fish assemblages and their associated habitats. Stereo-video methods provide highly accurate estimates of body-size, range and sampling area as well as a permanent record that can be cross-checked or resampled for additional data. Due to these advantages, diver-operated stereo-video (stereo-DOV) is becoming an increasingly popular alternative to underwater visual census. We provide a comprehensive guide for researchers using stereo-DOVs to survey fish assemblages and their associated habitat. Information on stereo-DOV design, video camera settings, field operations and video analysis are outlined. StereoâDOV surveys permit rapid and simultaneous collection of data on fish diversity, abundance, length and behaviour as well as their associated habitat. However, biases associated with diver presence in the water and variation in detectability should be considered and are dependent on the location and focal species of the survey. We recommend using stereo-DOVs for diver-based surveys of non-cryptic fish assemblages, given the advantages described. An increased uptake of this methodology, following the standard procedures described herein, will reduce variation in methodology, assist in the synthesis of data on continental and global scales and provide accurate information to improve fisheries management and conservation.},
  doi      = {https://doi.org/10.1111/2041-210X.13189},
  eprint   = {https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13189},
  groups   = {Stereo Camera, Fish Analysis},
  keywords = {biodiversity, conservation, fish assemblages, fisheries management, monitoring, sampling, stereo video, surveys},
  url      = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13189},
}

@Article{HakkiCanKaraimer,
  author = {Hakki Can Karaimer, Michael S. Brown},
  title  = {A Software Platform for Manipulating the Camera Imaging Pipeline},
  doi    = {https://doi.org/10.1007/978-3-319-46448-0_26},
  groups = {Image Processing},
}

@Article{Hamid2022,
  author    = {Mohd Saad Hamid and NurulFajar Abd Manap and Rostam Affendi Hamzah and Ahmad Fauzan Kadmin},
  journal   = {Journal of King Saud University - Computer and Information Sciences},
  title     = {Stereo matching algorithm based on deep learning: A survey},
  year      = {2022},
  month     = {may},
  number    = {5},
  pages     = {1663--1673},
  volume    = {34},
  doi       = {10.1016/j.jksuci.2020.08.011},
  groups    = {Stereo Camera},
  publisher = {Elsevier {BV}},
}

@InProceedings{Hamilton2021,
  author = {Scott Hamilton and Rick Starr and Dean Wendt and Benjamin Ruttenberg and Jennifer Caselle and Brice Semmens and Lyall Bellquist and Steven Morgan and Tim Mulligan and Joe Tyburczy and Shelby Ziegler and Rachel Brooks and Grant Waltz and Erica Mason and Chris Honeyman and Sadie Small and Jay Staton},
  title  = {CCFRP Final Report},
  year   = {2021},
  groups = {Ecology},
  url    = {https://caseagrant.ucsd.edu/sites/default/files/CCFRP_Final_Report.pdf},
}

@InProceedings{Harris1988,
  author       = {Harris, Chris and Stephens, Mike and others},
  booktitle    = {Alvey vision conference},
  title        = {A combined corner and edge detector},
  year         = {1988},
  number       = {50},
  organization = {Citeseer},
  pages        = {10--5244},
  volume       = {15},
  groups       = {Camera Calibration},
}

@Article{Harvey2001,
  author  = {Harvey, Euan and Fletcher, D. and Shortis, Mark},
  journal = {Fisheries Bulletin},
  title   = {A comparison of the precision and accuracy of estimates of reef-fish length made by divers and a stereo-video system},
  year    = {2001},
  month   = {01},
  pages   = {38-49},
  volume  = {36},
}

@Article{Harvey2002,
  author    = {Harvey, Euan and Fletcher, David and Shortis, Mark},
  journal   = {Fisheries Research},
  title     = {Estimation of reef fish length by divers and by stereo-video: a first comparison of the accuracy and precision in the field on living fish under operational conditions},
  year      = {2002},
  number    = {3},
  pages     = {255--265},
  volume    = {57},
  groups    = {Fish Analysis},
  publisher = {Elsevier},
}

@Article{Heppell2012,
  author    = {Scott A. Heppell and Brice X. Semmens and Stephanie K. Archer and Christy V. Pattengill-Semmens and Philippe G. Bush and Croy M. McCoy and Selina S. Heppell and Bradley C. Johnson},
  journal   = {Biological Conservation},
  title     = {Documenting recovery of a spawning aggregation through size frequency analysis from underwater laser calipers measurements},
  year      = {2012},
  month     = {oct},
  pages     = {119--127},
  volume    = {155},
  doi       = {10.1016/j.biocon.2012.06.002},
  groups    = {Ecology},
  publisher = {Elsevier {BV}},
}

@Article{Hu2023,
  author  = {Xiao Hu and F. Lauze and Kim Steenstrup Pedersen},
  journal = {International Journal of Computer Vision},
  title   = {Refractive Pose Refinement},
  year    = {2023},
  pages   = {1448-1476},
  volume  = {131},
  doi     = {10.1007/s11263-023-01763-4},
  groups  = {Stereo Camera, Optics},
}

@Article{Huang2020,
  author    = {Guangyi Huang and Yongyi Gong and Qingzhen Xu and Kanoksak Wattanachote and Kun Zeng and Xiaonan Luo},
  journal   = {{IEEE} Access},
  title     = {A Convolutional Attention Residual Network for Stereo Matching},
  year      = {2020},
  pages     = {50828--50842},
  volume    = {8},
  doi       = {10.1109/access.2020.2980243},
  groups    = {Stereo Camera},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Huntingford2013,
  author    = {F. A. Huntingford and F. L. Bor{\c{c}}ato and F. O. Mesquita},
  journal   = {Journal of Fish Biology},
  title     = {Identifying individual common carp Cyprinus carpio using scale pattern},
  year      = {2013},
  month     = {oct},
  number    = {5},
  pages     = {1453--1458},
  volume    = {83},
  doi       = {10.1111/jfb.12246},
  groups    = {Fish Analysis},
  publisher = {Wiley},
}

@Article{Hutchings2004,
  author   = {Hutchings, Jeffrey A. and Reynolds, John D.},
  journal  = {BioScience},
  title    = {{Marine Fish Population Collapses: Consequences for Recovery and Extinction Risk}},
  year     = {2004},
  issn     = {0006-3568},
  month    = {04},
  number   = {4},
  pages    = {297-309},
  volume   = {54},
  abstract = {{Rapid declines threaten the persistence of many marine fish. Data from more than 230 populations reveal a median reduction of 83\\% in breeding population size from known historic levels. Few populations recover rapidly; most exhibit little or no change in abundance up to 15 years after a collapse. Reductions in fishing pressure, although clearly necessary for population recovery, are often insufficient. Persistence and recovery are also influenced by life history, habitat alteration, changes to species assemblages, genetic responses to exploitation, and reductions in population growth attributable to the Allee effect, also known as depensation. Heightened extinction risks were highlighted recently when a Canadian population of Atlantic cod (Gadus morhua) was listed as endangered, on the basis of declines as high as 99.9\\% over 30 years. Unprecedented reductions in abundance and surprisingly low rates of recovery draw attention to scientists' limited understanding of how fish behavior, habitat, ecology, and evolution affect population growth at low abundance. Failure to prevent population collapses, and to take the conservation biology of marine fishes seriously, will ensure that many severely depleted species remain ecological and numerical shadows in the ecosystems that they once dominated.}},
  doi      = {10.1641/0006-3568(2004)054[0297:MFPCCF]2.0.CO;2},
  eprint   = {https://academic.oup.com/bioscience/article-pdf/54/4/297/26895516/54-4-297.pdf},
  groups   = {Ecology},
  url      = {https://doi.org/10.1641/0006-3568(2004)054[0297:MFPCCF]2.0.CO;2},
}

@Article{Huttenlocher1993,
  author    = {D.P. Huttenlocher and G.A. Klanderman and W.J. Rucklidge},
  journal   = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
  title     = {Comparing images using the Hausdorff distance},
  year      = {1993},
  number    = {9},
  pages     = {850--863},
  volume    = {15},
  doi       = {10.1109/34.232073},
  groups    = {Image Processing},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{JanuchowskiHartley2011,
  author    = {Fraser A. Januchowski-Hartley and Nicholas A. J. Graham and David A. Feary and Tau Morove and Joshua E. Cinner},
  journal   = {{PLoS} {ONE}},
  title     = {Fear of Fishers: Human Predation Explains Behavioral Changes in Coral Reef Fishes},
  year      = {2011},
  month     = {aug},
  number    = {8},
  pages     = {e22761},
  volume    = {6},
  doi       = {10.1371/journal.pone.0022761},
  editor    = {Julian Clifton},
  groups    = {Ecology, Fish Analysis},
  publisher = {Public Library of Science ({PLoS})},
}

@Article{Jaquet2006,
  author   = {Jaquet, Nathalie},
  journal  = {Marine Mammal Science},
  title    = {A SIMPLE PHOTOGRAMMETRIC TECHNIQUE TO MEASURE SPERM WHALES AT SEA},
  year     = {2006},
  number   = {4},
  pages    = {862-879},
  volume   = {22},
  abstract = {Abstract Knowledge of whale length is important to ecological studies. However, photographic techniques to measure sperm whales traditionally require high vantage points or a complicated stereo system. Furthermore, these traditional techniques require an alongside approach that often prevents individual identification. For simple and fast size measurements at sea, I used a laser range finder alongside a digital camera to obtain distance to the fluke at the same time as photo-identification. The camera/lens and laser range finder were calibrated on objects of known lengths. The coefficient of variation (CV) for test objects was low (CV = 0.21\%). Forty-seven individually identified sperm whales were measured repetitively on up to 12 different occasions, and the CV was lower (CV = 1.3\%) than for other photogrammetric techniques (CV = 4.4\%â5.1\%). A regression of log fluke span to log total length from whaling and stranding data yielded an râ2 of 0.87 (CV of residuals = 6.7\%). Thirty-eight female/immature sperm whales were measured in the Gulf of Mexico (median = 9.3 m, range = 7.1â12.3 m), 167 in the Gulf of California (median = 10.7 m, range = 8.4â13.1 m) and 13 bachelor males off Kaikoura, New Zealand (median = 14.2, range = 11.7â15.8 m). The results were within known sperm whale size and suggested that the population in the Gulf of Mexico was made up of smaller animals than that of the Gulf of California. This technique is easy to implement and allows the measurement of identified individuals.},
  doi      = {https://doi.org/10.1111/j.1748-7692.2006.00060.x},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1748-7692.2006.00060.x},
  groups   = {Fish Analysis, Laser Rangefinder},
  keywords = {sperm whale, Physeter macrocephalus, photogrammetry, length distribution},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1748-7692.2006.00060.x},
}

@Book{Jennings2001,
  author    = {Jennings, Simon and Kaiser, Michel J. and Reynolds, John D.},
  publisher = {Blackwell Science},
  title     = {Marine fisheries ecology},
  year      = {2001},
  address   = {Oxford ;},
  isbn      = {9781444311358},
  abstract  = {"This textbook describes fisheries exploitation, biology, conservation and management, and reflects many recent and important changes in fisheries science. These include growing concerns about the environmental impacts of fisheries, the role of ecological interactions in determining population dynamics, and the incorporation of uncertainty and precautionary principles into management advice. The book draws upon examples from tropical, temperate and polar environments, and provides readers with a broad understanding of the biological, economic and social aspects of fisheries ecology and the interplay between them. As well as covering 'classical' fisheries science, the book focuses on contemporary issues such as industrial fishing, poverty and conflict in fishing communities, marine reserves, the effects of fishing on coral reefs and by-catches of mammals, seabirds and reptiles. The book is primarily written for students of fisheries science and marine ecology, but should also appeal to practising fisheries scientists and those interested in conservation and the impacts of humans on the marine environment."--BOOK JACKET.},
  booktitle = {Marine fisheries ecology},
  groups    = {Fish Analysis},
  keywords  = {Ecologie marine.},
  language  = {eng},
}

@Article{JERALDS.2008,
  author    = {JERALD S. AULT and STEVEN G. SMITH and JIANGANG LUO and MARK E. MONACO and RICHARD S. APPELDOORN},
  journal   = {Environmental Conservation},
  title     = {Length-based assessment of sustainability benchmarks for coral reef fishes in Puerto Rico},
  year      = {2008},
  month     = {sep},
  number    = {3},
  pages     = {221--231},
  volume    = {35},
  doi       = {10.1017/s0376892908005043},
  groups    = {Ecology},
  publisher = {Cambridge University Press ({CUP})},
}

@Article{Knausgaard2021,
  author    = {Kristian Muri Knausg{\aa}rd and Arne Wiklund and Tonje Knutsen S{\o}rdalen and Kim Tallaksen Halvorsen and Alf Ring Kleiven and Lei Jiao and Morten Goodwin},
  journal   = {Applied Intelligence},
  title     = {Temperate fish detection and classification: a deep learning based approach},
  year      = {2021},
  month     = {mar},
  number    = {6},
  pages     = {6988--7001},
  volume    = {52},
  doi       = {10.1007/s10489-020-02154-9},
  groups    = {Fish Analysis},
  publisher = {Springer Science and Business Media {LLC}},
}

@InProceedings{Kunz2008,
  author    = {Clayton Kunz and Hanumant Singh},
  booktitle = {{OCEANS} 2008},
  title     = {Hemispherical refraction and camera calibration in underwater vision},
  year      = {2008},
  publisher = {{IEEE}},
  doi       = {10.1109/oceans.2008.5151967},
  groups    = {Camera Calibration},
}

@Article{Lavest2003,
  author    = {J.M. Lavest and G. Rives and J.T. Laprest�},
  journal   = {Machine Vision and Applications},
  title     = {Dry camera calibration for underwater applications},
  year      = {2003},
  month     = {mar},
  number    = {5-6},
  pages     = {245--253},
  volume    = {13},
  doi       = {10.1007/s00138-002-0112-z},
  groups    = {Camera Calibration},
  publisher = {Springer Science and Business Media {LLC}},
}

@PhdThesis{Lee2017,
  author   = {Lee, Yeejin},
  school   = {University of California, San Diego},
  title    = {Analysis of Raw Sensor Data with Applications in Image Processing and Compression},
  year     = {2017},
  type     = {phdthesis},
  abstract = {In the last few years, there has been a drastic improvement in the development of sensor technology that increases spatial resolution, dynamic range, and low-light sensitivity of digital cameras. Although the image processing techniques in a digital camera processing pipeline have been well studied, they face many difficulties in processing raw data of high resolution as well as raw data captured in the low light environment.

The key to maximizing the quality of the final output images is to understand the captured raw sensor data in the proper context of a camera processing pipeline. In this dissertation, we analyze the image acquisition model and develop new image processing techniques that leverage the acquisition model. This work advances computer vision and data communication by focusing on the role that the camera processing pipeline plays. Particularly, we discuss image enhancement in low-light condition and image compression problems in the context of the image pipeline.

To the best of our knowledge, this is the first study connecting image enhancement and compression algorithms to the context of an actual image acquisition process. Most prior image enhancement and image compression for raw sensor data used images already processed by camera processing pipelines for experimental verification while we verify the proposed image processing technique using actual sensor data.},
  groups   = {Image Processing},
  url      = {https://escholarship.org/uc/item/4063t2j4},
}

@Book{Leibe,
  author    = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
  publisher = {Springer},
  title     = {Computer Vision – ECCV 2016 14th European Conference, Amsterdam, The Netherlands, October 11–14, 2016, Proceedings, Part I},
  isbn      = {9783319464473},
  groups    = {Image Processing},
  pages     = {902},
  subtitle  = {14th European Conference, Amsterdam, The Netherlands, October 11–14, 2016, Proceedings, Part I},
}

@Article{Liang2021,
  author    = {Zhengfa Liang and Yulan Guo and Yiliu Feng and Wei Chen and Linbo Qiao and Li Zhou and Jianfeng Zhang and Hengzhu Liu},
  journal   = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
  title     = {Stereo Matching Using Multi-Level Cost Volume and Multi-Scale Feature Constancy},
  year      = {2021},
  month     = {jan},
  number    = {1},
  pages     = {300--315},
  volume    = {43},
  doi       = {10.1109/tpami.2019.2928550},
  groups    = {Stereo Camera},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Lowe2004,
  author    = {David G. Lowe},
  journal   = {International Journal of Computer Vision},
  title     = {Distinctive Image Features from Scale-Invariant Keypoints},
  year      = {2004},
  month     = {nov},
  number    = {2},
  pages     = {91--110},
  volume    = {60},
  doi       = {10.1023/b:visi.0000029664.99615.94},
  groups    = {Image Processing},
  publisher = {Springer Science and Business Media {LLC}},
}

@InProceedings{Lu2019,
  author    = {Shuigen Lu and Hesheng Yin and Yunliang Zhu and Xi Yang and Shaomiao Li and Bo Huang},
  booktitle = {Proceedings of the 2019 4th International Conference on Robotics, Control and Automation},
  title     = {Binocular Stereo Matching Based on Convolutional Neural Networks},
  year      = {2019},
  month     = {jul},
  publisher = {{ACM}},
  doi       = {10.1145/3351180.3351189},
  groups    = {Stereo Camera},
}

@Article{Luczynski2017,
  author    = {Tomasz {\L}uczy{\'{n}}ski and Max Pfingsthorn and Andreas Birk},
  journal   = {Ocean Engineering},
  title     = {The Pinax-model for accurate and efficient refraction correction of underwater cameras in flat-pane housings},
  year      = {2017},
  month     = {mar},
  pages     = {9--22},
  volume    = {133},
  doi       = {10.1016/j.oceaneng.2017.01.029},
  groups    = {Optics},
  publisher = {Elsevier {BV}},
}

@PhdThesis{Luczynski2018,
  author = {Tomasz Łuczyński},
  title  = {An Intelligent and Robust System for Underwater Vision},
  year   = {2018},
  groups = {Optics},
  url    = {http://nbn-resolving.org/urn:nbn:de:gbv:579-opus-1007798},
}

@Article{Mallet2014,
  author   = {Delphine Mallet and Dominique Pelletier},
  journal  = {Fisheries Research},
  title    = {Underwater video techniques for observing coastal marine biodiversity: A review of sixty years of publications (1952-2012)},
  year     = {2014},
  issn     = {0165-7836},
  pages    = {44-62},
  volume   = {154},
  abstract = {Underwater video techniques are increasingly used in marine ecology studies. Technological progress regarding video cameras, sensors (such as sounders), battery life and information storage make these techniques now accessible to a majority of users. However, diver-based underwater visual censuses, and catch and effort data, remain the most commonly used for observing coastal biodiversity and species. In this paper, we review the underwater video techniques that have been developed since the 1950s to investigate and/or monitor coastal biodiversity. Techniques such as remote underwater video, whether baited or not, diver-operated video and towed video are described, along with corresponding applications in the field. We then analyse the complementary of techniques, first from studies comparing video techniques with other observation techniques, whether video-based or not, and second by documenting their respective cost efficiencies. These findings are discussed with respect to current challenges in monitoring and investigating coastal biodiversity. Video should be more often considered and used, either in addition to or as an alternative to diver-based, fishing and acoustic techniques, as it may be particularly suited for monitoring coastal biodiversity in a variety of areas and on larger scales than hitherto and within an ecosystem-based approach to management and conservation.},
  doi      = {https://doi.org/10.1016/j.fishres.2014.01.019},
  groups   = {Fish Analysis, Stereo Camera},
  keywords = {Underwater video, Monitoring, Coastal biodiversity, Fish, Habitat},
  url      = {https://www.sciencedirect.com/science/article/pii/S0165783614000356},
}

@Article{Marchand2016,
  author      = {Marchand, Eric and Uchiyama, Hideaki and Spindler, Fabien},
  journal     = {{IEEE Transactions on Visualization and Computer Graphics}},
  title       = {{Pose Estimation for Augmented Reality: A Hands-On Survey}},
  year        = {2016},
  month       = Dec,
  number      = {12},
  pages       = {2633 - 2651},
  volume      = {22},
  doi         = {10.1109/TVCG.2015.2513408},
  groups      = {Camera Calibration},
  hal_id      = {hal-01246370},
  hal_version = {v1},
  keywords    = {Index Terms-Survey ; augmented reality ; vision-based camera localization ; pose estimation ; PnP ; SLAM ; motion estimation ; homography ; keypoint matching ; code examples},
  pdf         = {https://inria.hal.science/hal-01246370/file/survey-ieee-v2.pdf},
  publisher   = {{Institute of Electrical and Electronics Engineers}},
  url         = {https://inria.hal.science/hal-01246370},
}

@InProceedings{Mei2021,
  author    = {Jie Mei and Jenq-Neng Hwang and Suzanne Romain and Craig Rose and Braden Moore and Kelsey Magrane},
  booktitle = {{ICASSP} 2021 - 2021 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
  title     = {Absolute 3d Pose Estimation and Length Measurement of Severely Deformed Fish from Monocular Videos in Longline Fishing},
  year      = {2021},
  month     = {jun},
  publisher = {{IEEE}},
  doi       = {10.1109/icassp39728.2021.9414803},
  groups    = {Fish Analysis},
}

@Article{Menna2016,
  author    = {Fabio Menna and Erica Nocerino and Francesco Fassi and Fabio Remondino},
  journal   = {Sensors},
  title     = {Geometric and Optic Characterization of a Hemispherical Dome Port for Underwater Photogrammetry},
  year      = {2016},
  month     = {jan},
  number    = {1},
  pages     = {48},
  volume    = {16},
  doi       = {10.3390/s16010048},
  groups    = {Optics},
  publisher = {{MDPI} {AG}},
}

@Article{Monkman2019,
  author   = {Monkman, Graham G and Hyder, Kieran and Kaiser, Michel J and Vidal, Franck P},
  journal  = {ICES Journal of Marine Science},
  title    = {{Accurate estimation of fish length in single camera photogrammetry with a fiducial marker}},
  year     = {2019},
  issn     = {1054-3139},
  month    = {03},
  number   = {6},
  pages    = {2245-2254},
  volume   = {77},
  abstract = {{Videogrammetry and photogrammetry are increasingly being used in marine science for unsupervised data collection. The camera systems employed are complex, in contrast to “consumer” digital cameras and smartphones carried by potential citizen scientists. However, using consumer cameras in photogrammetry will introduce unknown length estimation errors through both the image acquisition process and lens distortion. This study presents a methodology to achieve accurate 2-dimensional (2-D) total length (TL) estimates of fish without specialist equipment or proprietary software. Photographs of fish were captured with an action camera using a background fiducial marker, a foreground fiducial marker and a laser marker. The geometric properties of the lens were modelled with OpenCV to correct image distortion. TL estimates were corrected for parallax effects using an algorithm requiring only the initial length estimate and known fish morphometric relationships. Correcting image distortion decreased RMSE by 96\\% and the percentage mean bias error (\\%MBE) by 50\\%. Correcting for parallax effects achieved a \\%MBE of −0.6\\%. This study demonstrates that the morphometric measurement of different species can be accurately estimated without the need for complex camera equipment, making it particularly suitable for deployment in citizen science and other volunteer-based data collection endeavours.}},
  doi      = {10.1093/icesjms/fsz030},
  eprint   = {https://academic.oup.com/icesjms/article-pdf/77/6/2245/38496874/fsz030.pdf},
  groups   = {Fish Analysis, Laser Rangefinder},
  url      = {https://doi.org/10.1093/icesjms/fsz030},
}

@Article{Mora2013,
  author    = {Camilo Mora and Chih-Lin Wei and Audrey Rollo and Teresa Amaro and Amy R. Baco and David Billett and Laurent Bopp and Qi Chen and Mark Collier and Roberto Danovaro and Andrew J. Gooday and Benjamin M. Grupe and Paul R. Halloran and Jeroen Ingels and Daniel O. B. Jones and Lisa A. Levin and Hideyuki Nakano and Karl Norling and Eva Ramirez-Llodra and Michael Rex and Henry A. Ruhl and Craig R. Smith and Andrew K. Sweetman and Andrew R. Thurber and Jerry F. Tjiputra and Paolo Usseglio and Les Watling and Tongwen Wu and Moriaki Yasuhara},
  journal   = {{PLoS} Biology},
  title     = {Biotic and Human Vulnerability to Projected Changes in Ocean Biogeochemistry over the 21st Century},
  year      = {2013},
  month     = {oct},
  number    = {10},
  pages     = {e1001682},
  volume    = {11},
  doi       = {10.1371/journal.pbio.1001682},
  editor    = {Georgina M. Mace},
  groups    = {Ecology},
  publisher = {Public Library of Science ({PLoS})},
}

@Article{Mueller2006,
  author    = {Robert P. Mueller and Richard S. Brown and Haakon Hop and Larry Moulton},
  journal   = {Reviews in Fish Biology and Fisheries},
  title     = {Video and acoustic camera techniques for studying fish under ice: a review and comparison},
  year      = {2006},
  month     = {sep},
  number    = {2},
  pages     = {213--226},
  volume    = {16},
  doi       = {10.1007/s11160-006-9011-0},
  groups    = {Acoustic Camera},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Myers2003,
  author    = {Ransom A. Myers and Boris Worm},
  journal   = {Nature},
  title     = {Rapid worldwide depletion of predatory fish communities},
  year      = {2003},
  month     = {may},
  number    = {6937},
  pages     = {280--283},
  volume    = {423},
  doi       = {10.1038/nature01610},
  groups    = {Ecology},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Nguyen1995,
  author  = {Nguyen, Hoa G and Blackburn, Michael R},
  journal = {Technical Document},
  title   = {A simple method for range finding via laser triangulation},
  year    = {1995},
  volume  = {2734},
  groups  = {Laser Rangefinder},
}

@Manual{OrbittyGPIO,
  title  = {Orbitty Carrier and Jetson TX2: GPIO pins - Product support / balenaOS},
  groups = {RealSense System},
  url    = {https://forums.balena.io/t/orbitty-carrier-and-jetson-tx2-gpio-pins/5306},
}

@Manual{OrbittyManual,
  title  = {Orbitty Carrier for NVIDIA® Jetson™ TX2/TX2i},
  groups = {RealSense System},
  url    = {http://connecttech.com/pdf/CTIM-ASG003_Manual.pdf},
}

@InProceedings{Parthasarathy1982,
  author       = {S. Parthasarathy and J. Birk and J. Dessimoz},
  booktitle    = {Robot Vision},
  title        = {{Laser Rangefinder For Robot Control And Inspection}},
  year         = {1982},
  editor       = {Azriel Rosenfeld},
  organization = {International Society for Optics and Photonics},
  pages        = {2 -- 11},
  publisher    = {SPIE},
  volume       = {0336},
  doi          = {10.1117/12.933605},
  groups       = {Laser Rangefinder},
  url          = {https://doi.org/10.1117/12.933605},
}

@MastersThesis{Paxson2022,
  author   = {Patrick Richard Paxson},
  school   = {University of California San Diego},
  title    = {Systems Design of Underwater 3-D Camera Modules},
  year     = {2022},
  type     = {mathesis},
  abstract = {Methods for measuring fish populations are incredibly outdated. Even with rapid improvements in battery technology, compute power and camera systems in the last few years, the most popular techniques for counting fish and measuring their lengths employ humans. In this paper, I present FishSense as an alternative. By utilizing a compact 3-D camera, powerful embedded compute system, and easily-available off-the-shelf parts for assembly, the FishSense modules are sleek, cost-effective and modular systems able to slot into a wide variety of applications. By capturing both depth and color image data, these modules are able to measure the length of individual fish as well, offering an effective non-invasive solution to length \& biomass estimation. The hardware design allows for a high degree of modularity, with options for longer battery life, better performance, and applications in longer-term passive monitoring. The FishSense handheld model has been rigorously tested in several deployments, ranging from a small testing pool with toy fish, to a 70,000 gallon aquarium tank, to an active aquaculture center, with more planned in upcoming months, and preliminary software results from these deployments demonstrate the efficacy of the FishSense modules at measuring fish populations and sizes.},
  groups   = {RealSense System},
  url      = {https://escholarship.org/uc/item/3221z5rm},
}

@Article{Pet2005,
  author    = {Jos S. Pet and Peter J. Mous and Andreas H. Muljadi and Yvonne J. Sadovy and Lyle Squire},
  journal   = {Environmental Biology of Fishes},
  title     = {Aggregations of Plectropomus areolatus and Epinephelus fuscoguttatus (groupers, Serranidae) in the Komodo National Park, Indonesia: Monitoring and Implications for Management},
  year      = {2005},
  month     = {oct},
  number    = {2},
  pages     = {209--218},
  volume    = {74},
  doi       = {10.1007/s10641-005-8528-8},
  groups    = {Fish Analysis, Ecology},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Pignatelli2010,
  author    = {Vincenzo Pignatelli and Conor Champ and Justin Marshall and Misha Vorobyev},
  journal   = {Biology Letters},
  title     = {Double cones are used for colour discrimination in the reef fish,Rhinecanthus aculeatus},
  year      = {2010},
  month     = {feb},
  number    = {4},
  pages     = {537--539},
  volume    = {6},
  doi       = {10.1098/rsbl.2009.1010},
  groups    = {Ecology},
  publisher = {The Royal Society},
}

@Article{Pontecorvo1980,
  author    = {Giulio Pontecorvo and Maurice Wilkinson and Ronald Anderson and Michael Holdowsky},
  journal   = {Science},
  title     = {Contribution of the Ocean Sector to the United States Economy},
  year      = {1980},
  month     = {may},
  number    = {4447},
  pages     = {1000--1006},
  volume    = {208},
  doi       = {10.1126/science.208.4447.1000},
  groups    = {Ecology},
  publisher = {American Association for the Advancement of Science ({AAAS})},
}

@Book{RafaelC.Gonzalez2018,
  author    = {Rafael C. Gonzalez, Richard E. Woods},
  publisher = {Pearson},
  title     = {Digital Image Processing},
  year      = {2018},
  isbn      = {978-0-13-168728-8},
  groups    = {Image Processing, Fish Analysis},
}

@Article{Raistrick2023,
  author        = {Raistrick, Alexander and Lipson, Lahav and Ma, Zeyu and Mei, Lingjie and Wang, Mingzhe and Zuo, Yiming and Kayan, Karhan and Wen, Hongyu and Han, Beining and Wang, Yihan and Newell, Alejandro and Law, Hei and Goyal, Ankit and Yang, Kaiyu and Deng, Jia},
  title         = {Infinite Photorealistic Worlds using Procedural Generation},
  year          = {2023},
  month         = jun,
  abstract      = {We introduce Infinigen, a procedural generator of photorealistic 3D scenes of the natural world. Infinigen is entirely procedural: every asset, from shape to texture, is generated from scratch via randomized mathematical rules, using no external source and allowing infinite variation and composition. Infinigen offers broad coverage of objects and scenes in the natural world including plants, animals, terrains, and natural phenomena such as fire, cloud, rain, and snow. Infinigen can be used to generate unlimited, diverse training data for a wide range of computer vision tasks including object detection, semantic segmentation, optical flow, and 3D reconstruction. We expect Infinigen to be a useful resource for computer vision research and beyond. Please visit https://infinigen.org for videos, code and pre-generated data.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2306.09310},
  eprint        = {2306.09310},
  file          = {:http\://arxiv.org/pdf/2306.09310v2:PDF},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  publisher     = {arXiv},
}

@Article{Ramsay2009,
  author    = {Ramsay, JM and Watral, V and Schreck, CB and Kent, ML},
  journal   = {Journal of Fish Diseases},
  title     = {Husbandry stress exacerbates mycobacterial infections in adult zebrafish, Danio rerio (Hamilton)},
  year      = {2009},
  number    = {11},
  pages     = {931--941},
  volume    = {32},
  groups    = {Fish Analysis},
  publisher = {Wiley Online Library},
}

@Article{Rankin2017,
  author    = {Polly S. Rankin and Robert W. Hannah and Matthew T.O. Blume and Timothy J. Miller-Morgan and Jerry R. Heidel},
  journal   = {Fisheries Research},
  title     = {Delayed effects of capture-induced barotrauma on physical condition and behavioral competency of recompressed yelloweye rockfish, Sebastes ruberrimus},
  year      = {2017},
  month     = {feb},
  pages     = {258--268},
  volume    = {186},
  doi       = {10.1016/j.fishres.2016.09.004},
  groups    = {Ecology},
  publisher = {Elsevier {BV}},
}

@Article{Raymond2007,
  author    = {EH Raymond and EA Widder},
  journal   = {Marine Ecology Progress Series},
  title     = {Behavioral responses of two deep-sea fish species to red, far-red, and white light},
  year      = {2007},
  month     = {nov},
  pages     = {291--298},
  volume    = {350},
  doi       = {10.3354/meps07196},
  groups    = {Ecology},
  publisher = {Inter-Research Science Center},
}

@Article{Rice2011,
  author    = {Jake C. Rice and Serge M. Garcia},
  journal   = {{ICES} Journal of Marine Science},
  title     = {Fisheries, food security, climate change, and biodiversity: characteristics of the sector and perspectives on emerging issues},
  year      = {2011},
  month     = {apr},
  number    = {6},
  pages     = {1343--1353},
  volume    = {68},
  doi       = {10.1093/icesjms/fsr041},
  groups    = {Ecology},
  publisher = {Oxford University Press ({OUP})},
}

@Article{Rizzo2016,
  author    = {Austin A. Rizzo and Stuart A. Welsh and Patricia A. Thompson},
  journal   = {North American Journal of Fisheries Management},
  title     = {A Paired-Laser Photogrammetric Method for In Situ Length Measurement of Benthic Fishes},
  year      = {2016},
  month     = {dec},
  number    = {1},
  pages     = {16--22},
  volume    = {37},
  doi       = {10.1080/02755947.2016.1235632},
  groups    = {Laser Rangefinder},
  publisher = {Wiley},
}

@Article{Rohner2011,
  author   = {Rohner, C. A. and Richardson, A. J. and Marshall, A. D. and Weeks, S. J. and Pierce, S. J.},
  journal  = {Journal of Fish Biology},
  title    = {How large is the world's largest fish? Measuring whale sharks Rhincodon typus with laser photogrammetry},
  year     = {2011},
  number   = {1},
  pages    = {378-385},
  volume   = {78},
  abstract = {Laser photogrammetry was found to be a promising new cost-effective technique for measuring free-swimming whale sharks Rhincodon typus. Photogrammetric measurements were more precise than visual size estimates by experienced researchers, with results from the two methods differing by 9Â· 8 Â± 1Â· 1\% (mean Â±s.e.). A new metric of total length and the length between the fifth gill and first dorsal fin (r2 = 0Â· 93) is proposed to facilitate easy, accurate length measurements of whale sharks in the field.},
  doi      = {https://doi.org/10.1111/j.1095-8649.2010.02861.x},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1095-8649.2010.02861.x},
  groups   = {Fish Analysis},
  keywords = {demography, growth, size, visual estimate},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1095-8649.2010.02861.x},
}

@Article{Schmid2000,
  author    = {Cordelia Schmid and Roger Mohr and Christian Bauckhage},
  journal   = {International Journal of Computer Vision},
  title     = {Evaluation of Interest Point Detectors},
  year      = {2000},
  number    = {2},
  pages     = {151--172},
  volume    = {37},
  doi       = {10.1023/a:1008199403446},
  groups    = {Image Processing},
  publisher = {Springer Science and Business Media {LLC}},
}

@Online{SeaGIS,
  author  = {SeaGIS},
  groups  = {Stereo Camera, Fish Analysis, Camera Calibration},
  title   = {Pricing of Popular Products},
  url     = {https://www.seagis.com.au/SeaGIS%20Prices.pdf},
  urldate = {2023-08-24},
  year    = {2023},
}

@Article{Shafait2017,
  author   = {Shafait, Faisal and Harvey, Euan S. and Shortis, Mark R. and Mian, Ajmal and Ravanbakhsh, Mehdi and Seager, James W. and Culverhouse, Philip F. and Cline, Danelle E. and Edgington, Duane R.},
  journal  = {ICES Journal of Marine Science},
  title    = {{Towards automating underwater measurement of fish length: a comparison of semi-automatic and manual stereo–video measurements}},
  year     = {2017},
  issn     = {1054-3139},
  month    = {02},
  number   = {6},
  pages    = {1690-1701},
  volume   = {74},
  abstract = {Underwater stereo–video systems are widely used for counting and measuring fish in aquaculture, fisheries, and conservation management. Length measurements are generated from stereo–video recordings by a software operator using a mouse to locate the head and tail of a fish in synchronized pairs of images. This data can be used to compare spatial and temporal changes in the mean length and biomass or frequency distributions of populations of fishes. Since the early 1990s stereo–video has also been used for measuring the lengths of fish in aquaculture for quota and farm management. However, the costs of the equipment, software, the time, and salary costs involved in post processing imagery manually and the subsequent delays in the availability of length information inhibit the adoption of this technology.We present a semi-automatic method for capturing stereo–video measurements to estimate the lengths of fish. We compare the time taken to make measurements of the same fish measured manually from stereo–video imagery to that measured semi-automatically. Using imagery recorded during transfers of Southern Bluefin Tuna (SBT) from tow cages to grow out cages, we demonstrate that the semi-automatic algorithm developed can obtain fork length measurements with an error of less than 1\\% of the true length and with at least a sixfold reduction in operator time in comparison to manual measurements. Of the 22 138 SBT recorded we were able to measure 52.6\\% (11 647) manually and 11.8\\% (2614) semi-automatically. For seven of the eight cage transfers recorde,d there were no statistical differences in the mean length, weight, or length frequency between manual and semi-automatic measurements. When the data were pooled across the eight cage transfers, there was no statistical difference in mean length or weight between the stereo–video-based manual and semi-automated measurements. Hence, the presented semi-automatic system can be deployed to significantly reduce the cost involved in adoption of stereo–video technology.},
  doi      = {10.1093/icesjms/fsx007},
  eprint   = {https://academic.oup.com/icesjms/article-pdf/74/6/1690/31246707/fsx007.pdf},
  groups   = {Fish Analysis, Stereo Camera},
  url      = {https://doi.org/10.1093/icesjms/fsx007},
}

@Article{Shi2020,
  author    = {Chen Shi and Qingbin Wang and Xinlei He and Xiaoshuan Zhang and Daoliang Li},
  journal   = {Computers and Electronics in Agriculture},
  title     = {An automatic method of fish length estimation using underwater stereo system based on {LabVIEW}},
  year      = {2020},
  month     = {jun},
  pages     = {105419},
  volume    = {173},
  doi       = {10.1016/j.compag.2020.105419},
  groups    = {Fish Analysis},
  publisher = {Elsevier {BV}},
}

@Article{Siddique2020,
  author        = {Siddique, Nahian and Sidike, Paheding and Elkin, Colin and Devabhaktuni, Vijay},
  journal       = {{IEEE} Access},
  title         = {U-Net and its variants for medical image segmentation: theory and applications},
  year          = {2020},
  month         = nov,
  pages         = {82031--82057},
  volume        = {9},
  abstract      = {U-net is an image segmentation technique developed primarily for medical image analysis that can precisely segment images using a scarce amount of training data. These traits provide U-net with a very high utility within the medical imaging community and have resulted in extensive adoption of U-net as the primary tool for segmentation tasks in medical imaging. The success of U-net is evident in its widespread use in all major image modalities from CT scans and MRI to X-rays and microscopy. Furthermore, while U-net is largely a segmentation tool, there have been instances of the use of U-net in other applications. As the potential of U-net is still increasing, in this review we look at the various developments that have been made in the U-net architecture and provide observations on recent trends. We examine the various innovations that have been made in deep learning and discuss how these tools facilitate U-net. Furthermore, we look at image modalities and application areas where U-net has been applied.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.1109/access.2021.3086020},
  eprint        = {2011.01118},
  file          = {:http\://arxiv.org/pdf/2011.01118v1:PDF},
  groups        = {Fish Analysis},
  keywords      = {Image and Video Processing (eess.IV), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences},
  primaryclass  = {eess.IV},
  publisher     = {Institute of Electrical and Electronics Engineers ({IEEE})},
}

@Article{Sinovcic2004,
  author    = {Sinov{\v{c}}i{\'c}, G and Frani{\v{c}}evi{\'c}, M and Zorica, B and {\v{C}}ike{\v{s}}-Ke{\v{c}}, V},
  journal   = {Journal of Applied Ichthyology},
  title     = {Length--weight and length--length relationships for 10 pelagic fish species from the Adriatic Sea (Croatia)},
  year      = {2004},
  number    = {2},
  pages     = {156--158},
  volume    = {20},
  groups    = {Fish Analysis},
  publisher = {Wiley Online Library},
}

@Article{Stien2017,
  author    = {L. H. Stien and J. Nilsson and S. Bui and J. E. Fosseidengen and T. S. Kristiansen and {\O}. {\O}verli and O. Folkedal},
  journal   = {Journal of Fish Biology},
  title     = {Consistent melanophore spot patterns allow long-term individual recognition of Atlantic salmon},
  year      = {2017},
  month     = {nov},
  number    = {6},
  pages     = {1699--1712},
  volume    = {91},
  doi       = {10.1111/jfb.13491},
  groups    = {Fish Analysis},
  publisher = {Wiley},
}

@Article{Stock2021,
  author    = {Brian C Stock and Scott A Heppell and Lynn Waterhouse and India C Dove and Christy V Pattengill-Semmens and Croy M McCoy and Phillippe G Bush and Gina Ebanks-Petrie and Brice X Semmens},
  journal   = {{ICES} Journal of Marine Science},
  title     = {Pulse recruitment and recovery of Cayman Islands Nassau Grouper (Epinephelus striatus) spawning aggregations revealed by in situ length-frequency data},
  year      = {2021},
  month     = {jan},
  number    = {1},
  pages     = {277--292},
  volume    = {78},
  doi       = {10.1093/icesjms/fsaa221},
  editor    = {Katherine Yates},
  groups    = {Stereo Camera},
  publisher = {Oxford University Press ({OUP})},
}

@Article{Suzuki1985,
  author    = {Satoshi Suzuki and Keiichi Abe},
  journal   = {Computer Vision, Graphics, and Image Processing},
  title     = {Topological structural analysis of digitized binary images by border following},
  year      = {1985},
  month     = {apr},
  number    = {1},
  pages     = {32--46},
  volume    = {30},
  doi       = {10.1016/0734-189x(85)90016-7},
  groups    = {Image Processing},
  publisher = {Elsevier {BV}},
}

@Article{Tankovich2020,
  author        = {Tankovich, Vladimir and Häne, Christian and Zhang, Yinda and Kowdle, Adarsh and Fanello, Sean and Bouaziz, Sofien},
  title         = {HITNet: Hierarchical Iterative Tile Refinement Network for Real-time Stereo Matching},
  year          = {2020},
  month         = jul,
  abstract      = {This paper presents HITNet, a novel neural network architecture for real-time stereo matching. Contrary to many recent neural network approaches that operate on a full cost volume and rely on 3D convolutions, our approach does not explicitly build a volume and instead relies on a fast multi-resolution initialization step, differentiable 2D geometric propagation and warping mechanisms to infer disparity hypotheses. To achieve a high level of accuracy, our network not only geometrically reasons about disparities but also infers slanted plane hypotheses allowing to more accurately perform geometric warping and upsampling operations. Our architecture is inherently multi-resolution allowing the propagation of information across different levels. Multiple experiments prove the effectiveness of the proposed approach at a fraction of the computation required by state-of-the-art methods. At the time of writing, HITNet ranks 1st-3rd on all the metrics published on the ETH3D website for two view stereo, ranks 1st on most of the metrics among all the end-to-end learning approaches on Middlebury-v3, ranks 1st on the popular KITTI 2012 and 2015 benchmarks among the published methods faster than 100ms.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2007.12140},
  eprint        = {2007.12140},
  file          = {:http\://arxiv.org/pdf/2007.12140v5:PDF},
  groups        = {Stereo Camera},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  publisher     = {arXiv},
}

@Article{Terhaar2022,
  author    = {Jens Terhaar and Thomas L. Frölicher and Fortunat Joos},
  journal   = {Biogeosciences},
  title     = {Observation-constrained estimates of the global ocean carbon sink from Earth system models},
  year      = {2022},
  month     = {sep},
  number    = {18},
  pages     = {4431--4457},
  volume    = {19},
  doi       = {10.5194/bg-19-4431-2022},
  groups    = {Ecology},
  publisher = {Copernicus {GmbH}},
}

@Article{Tonioni2018,
  author        = {Tonioni, Alessio and Tosi, Fabio and Poggi, Matteo and Mattoccia, Stefano and Di Stefano, Luigi},
  title         = {Real-time self-adaptive deep stereo},
  year          = {2018},
  month         = oct,
  abstract      = {Deep convolutional neural networks trained end-to-end are the state-of-the-art methods to regress dense disparity maps from stereo pairs. These models, however, suffer from a notable decrease in accuracy when exposed to scenarios significantly different from the training set, e.g., real vs synthetic images, etc.). We argue that it is extremely unlikely to gather enough samples to achieve effective training/tuning in any target domain, thus making this setup impractical for many applications. Instead, we propose to perform unsupervised and continuous online adaptation of a deep stereo network, which allows for preserving its accuracy in any environment. However, this strategy is extremely computationally demanding and thus prevents real-time inference. We address this issue introducing a new lightweight, yet effective, deep stereo architecture, Modularly ADaptive Network (MADNet) and developing a Modular ADaptation (MAD) algorithm, which independently trains sub-portions of the network. By deploying MADNet together with MAD we introduce the first real-time self-adaptive deep stereo system enabling competitive performance on heterogeneous datasets.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1810.05424},
  eprint        = {1810.05424},
  file          = {:http\://arxiv.org/pdf/1810.05424v2:PDF},
  groups        = {Stereo Camera},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  publisher     = {arXiv},
}

@InProceedings{Tueller2021,
  author    = {Peter Tueller and Raghav Maddukuri and Patrick Paxson and Vivaswat Suresh and Arjun Ashok and Madison Bland and Ronan Wallace and Julia Guerrero and Brice Semmens and Ryan Kastner},
  booktitle = {{OCEANS} 2021: San Diego {\textendash} Porto},
  title     = {{FishSense}: Underwater {RGBD} Imaging for Fish Measurement},
  year      = {2021},
  month     = {sep},
  publisher = {{IEEE}},
  doi       = {10.23919/oceans44145.2021.9705929},
  groups    = {RealSense System},
}

@Article{Tulyakov2018,
  author        = {Tulyakov, Stepan and Ivanov, Anton and Fleuret, Francois},
  title         = {Practical Deep Stereo (PDS): Toward applications-friendly deep stereo matching},
  year          = {2018},
  month         = jun,
  abstract      = {End-to-end deep-learning networks recently demonstrated extremely good perfor- mance for stereo matching. However, existing networks are difficult to use for practical applications since (1) they are memory-hungry and unable to process even modest-size images, (2) they have to be trained for a given disparity range. The Practical Deep Stereo (PDS) network that we propose addresses both issues: First, its architecture relies on novel bottleneck modules that drastically reduce the memory footprint in inference, and additional design choices allow to handle greater image size during training. This results in a model that leverages large image context to resolve matching ambiguities. Second, a novel sub-pixel cross- entropy loss combined with a MAP estimator make this network less sensitive to ambiguous matches, and applicable to any disparity range without re-training. We compare PDS to state-of-the-art methods published over the recent months, and demonstrate its superior performance on FlyingThings3D and KITTI sets.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.1806.01677},
  eprint        = {1806.01677},
  file          = {:http\://arxiv.org/pdf/1806.01677v1:PDF},
  groups        = {Stereo Camera},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  publisher     = {arXiv},
}

@Article{Valerio2018,
  author    = {Meghan Valerio and Ofri Mann and Nadav Shashar},
  journal   = {Marine Biology},
  title     = {{\textquotedblleft}Boo! Did we scare you?{\textquotedblright}: behavioral responses of reef-associated fish, prawn gobies (Amblyeleotris steinitzi and Amblyeleotris sungami) to anthropogenic diver disturbance},
  year      = {2018},
  month     = {nov},
  number    = {1},
  volume    = {166},
  doi       = {10.1007/s00227-018-3447-3},
  groups    = {Ecology, Fish Analysis},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Wang2022,
  author        = {Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  title         = {YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors},
  year          = {2022},
  month         = jul,
  abstract      = {YOLOv7 surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS and has the highest accuracy 56.8% AP among all known real-time object detectors with 30 FPS or higher on GPU V100. YOLOv7-E6 object detector (56 FPS V100, 55.9% AP) outperforms both transformer-based detector SWIN-L Cascade-Mask R-CNN (9.2 FPS A100, 53.9% AP) by 509% in speed and 2% in accuracy, and convolutional-based detector ConvNeXt-XL Cascade-Mask R-CNN (8.6 FPS A100, 55.2% AP) by 551% in speed and 0.7% AP in accuracy, as well as YOLOv7 outperforms: YOLOR, YOLOX, Scaled-YOLOv4, YOLOv5, DETR, Deformable DETR, DINO-5scale-R50, ViT-Adapter-B and many other object detectors in speed and accuracy. Moreover, we train YOLOv7 only on MS COCO dataset from scratch without using any other datasets or pre-trained weights. Source code is released in https://github.com/WongKinYiu/yolov7.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2207.02696},
  eprint        = {2207.02696},
  file          = {:http\://arxiv.org/pdf/2207.02696v1:PDF},
  groups        = {Fish Analysis},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  publisher     = {arXiv},
}

@Article{Wang2023,
  author        = {Wang, Weihan and Joshi, Bharat and Burgdorfer, Nathaniel and Batsos, Konstantinos and Li, Alberto Quattrini and Mordohai, Philippos and Rekleitis, Ioannis},
  title         = {Real-Time Dense 3D Mapping of Underwater Environments},
  year          = {2023},
  month         = apr,
  abstract      = {This paper addresses real-time dense 3D reconstruction for a resource-constrained Autonomous Underwater Vehicle (AUV). Underwater vision-guided operations are among the most challenging as they combine 3D motion in the presence of external forces, limited visibility, and absence of global positioning. Obstacle avoidance and effective path planning require online dense reconstructions of the environment. Autonomous operation is central to environmental monitoring, marine archaeology, resource utilization, and underwater cave exploration. To address this problem, we propose to use SVIn2, a robust VIO method, together with a real-time 3D reconstruction pipeline. We provide extensive evaluation on four challenging underwater datasets. Our pipeline produces comparable reconstruction with that of COLMAP, the state-of-the-art offline 3D reconstruction method, at high frame rates on a single CPU.},
  archiveprefix = {arXiv},
  copyright     = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
  doi           = {10.48550/ARXIV.2304.02704},
  eprint        = {2304.02704},
  file          = {:http\://arxiv.org/pdf/2304.02704v1:PDF},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), Robotics (cs.RO), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  publisher     = {arXiv},
}

@Article{Wanninkhof2013,
  author    = {R. Wanninkhof and G. -H. Park and T. Takahashi and C. Sweeney and R. Feely and Y. Nojiri and N. Gruber and S. C. Doney and G. A. McKinley and A. Lenton and C. Le Qu{\'{e}}r{\'{e}} and C. Heinze and J. Schwinger and H. Graven and S. Khatiwala},
  journal   = {Biogeosciences},
  title     = {Global ocean carbon uptake: magnitude, variability and trends},
  year      = {2013},
  month     = {mar},
  number    = {3},
  pages     = {1983--2000},
  volume    = {10},
  doi       = {10.5194/bg-10-1983-2013},
  groups    = {Ecology},
  publisher = {Copernicus {GmbH}},
}

@Conference{Wong2022,
  author    = {Emily Wong and Isabella Humphrey and Scott Switzer and Christopher Crutchfield and Nathan Hui and Curt Schurgers and Ryan Kastner},
  booktitle = {Proceedings of the 16th International Conference on Underwater Networks \& Systems},
  title     = {Underwater Depth Calibration Using a Commercial Depth Camera},
  year      = {2022},
  address   = {New York, NY, USA},
  month     = {12},
  pages     = {1–5},
  publisher = {Association for Computing Machinery},
  series    = {WUWNet '22},
  abstract  = {Depth cameras are increasingly used in research and industry in underwater settings. However, cameras that have been calibrated in air are notably inaccurate in depth measurements when placed underwater, and little research has been done to explore pre-existing depth calibration methodologies and their effectiveness in underwater environments. We used four methods of calibration on a low-cost, commercial depth camera both in and out of water. For each of these methods, we compared the predicted distance and length of objects from the camera with manually measured values to get an indication of depth and length accuracy. Our findings indicate that the standard methods of calibration in air are largely ineffective for underwater calibration and that custom calibration techniques are necessary to achieve higher accuracy.},
  day       = {29},
  doi       = {10.1145/3567600.3568158},
  groups    = {Camera Calibration, Stereo Camera, RealSense System},
  isbn      = {9781450399524},
  keywords  = {Underwater stereo vision, depth camera calibration},
  location  = {Boston, MA, USA},
  pagetotal = {5},
  url       = {https://doi.org/10.1145/3567600.3568158},
}

@Article{Yang2019,
  author  = {Miao Yang},
  journal = {IEEE Access},
  title   = {An In-Depth Survey of Underwater Image Enhancement and Restoration},
  year    = {2019},
  groups  = {Image Processing, Fish Analysis},
}

@InProceedings{Yang2020,
  author    = {Menglong Yang and Fangrui Wu and Wei Li},
  booktitle = {2020 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
  title     = {{WaveletStereo}: Learning Wavelet Coefficients of Disparity Map in Stereo Matching},
  year      = {2020},
  month     = {jun},
  publisher = {{IEEE}},
  doi       = {10.1109/cvpr42600.2020.01290},
  groups    = {Stereo Camera},
}

@Article{Yang2022,
  author    = {Hongbo Yang and Zhizun Xu and Baozhu Jia},
  journal   = {Sensors},
  title     = {An Underwater Positioning System for {UUVs} Based on {LiDAR} Camera and Inertial Measurement Unit},
  year      = {2022},
  month     = {jul},
  number    = {14},
  pages     = {5418},
  volume    = {22},
  doi       = {10.3390/s22145418},
  groups    = {Underwater Positioning},
  publisher = {{MDPI} {AG}},
}

@InProceedings{Yau2013,
  author    = {Timothy Yau and Minglun Gong and Yee-Hong Yang},
  booktitle = {2013 {IEEE} Conference on Computer Vision and Pattern Recognition},
  title     = {Underwater Camera Calibration Using Wavelength Triangulation},
  year      = {2013},
  month     = {jun},
  publisher = {{IEEE}},
  doi       = {10.1109/cvpr.2013.323},
  groups    = {Camera Calibration, Optics},
}

@Article{Zhang2000,
  author   = {Zhang, Z.},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title    = {A flexible new technique for camera calibration},
  year     = {2000},
  issn     = {1939-3539},
  month    = {Nov},
  number   = {11},
  pages    = {1330-1334},
  volume   = {22},
  abstract = {We propose a flexible technique to easily calibrate a camera. It only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one more step from laboratory environments to real world use.},
  doi      = {10.1109/34.888718},
  groups   = {Camera Calibration},
}

@Article{Zhang2020,
  author        = {Zhang, Jingyang and Yao, Yao and Luo, Zixin and Li, Shiwei and Shen, Tianwei and Fang, Tian and Quan, Long},
  title         = {Learning Stereo Matchability in Disparity Regression Networks},
  year          = {2020},
  month         = aug,
  abstract      = {Learning-based stereo matching has recently achieved promising results, yet still suffers difficulties in establishing reliable matches in weakly matchable regions that are textureless, non-Lambertian, or occluded. In this paper, we address this challenge by proposing a stereo matching network that considers pixel-wise matchability. Specifically, the network jointly regresses disparity and matchability maps from 3D probability volume through expectation and entropy operations. Next, a learned attenuation is applied as the robust loss function to alleviate the influence of weakly matchable pixels in the training. Finally, a matchability-aware disparity refinement is introduced to improve the depth inference in weakly matchable regions. The proposed deep stereo matchability (DSM) framework can improve the matching result or accelerate the computation while still guaranteeing the quality. Moreover, the DSM framework is portable to many recent stereo networks. Extensive experiments are conducted on Scene Flow and KITTI stereo datasets to demonstrate the effectiveness of the proposed framework over the state-of-the-art learning-based stereo methods.},
  archiveprefix = {arXiv},
  copyright     = {arXiv.org perpetual, non-exclusive license},
  doi           = {10.48550/ARXIV.2008.04800},
  eprint        = {2008.04800},
  file          = {:http\://arxiv.org/pdf/2008.04800v1:PDF},
  groups        = {Stereo Camera},
  keywords      = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
  primaryclass  = {cs.CV},
  publisher     = {arXiv},
}

@Misc{Zhao2017,
  author    = {Zhao, Hengshuang and Qi, Xiaojuan and Shen, Xiaoyong and Shi, Jianping and Jia, Jiaya},
  title     = {ICNet for Real-Time Semantic Segmentation on High-Resolution Images},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license},
  doi       = {10.48550/ARXIV.1704.08545},
  groups    = {Fish Analysis},
  keywords  = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  publisher = {arXiv},
}

@Article{Zhou2010,
  author    = {Yu Zhou},
  journal   = {Robotica},
  title     = {A closed-form algorithm for the least-squares trilateration problem},
  year      = {2010},
  month     = {may},
  number    = {3},
  pages     = {375--389},
  volume    = {29},
  doi       = {10.1017/s0263574710000196},
  groups    = {Stereo Camera},
  publisher = {Cambridge University Press ({CUP})},
}

@Article{Zhou2020,
  author    = {Kun Zhou and Xiangxi Meng and Bo Cheng},
  journal   = {Computational Intelligence and Neuroscience},
  title     = {Review of Stereo Matching Algorithms Based on Deep Learning},
  year      = {2020},
  month     = {mar},
  pages     = {1--12},
  volume    = {2020},
  doi       = {10.1155/2020/8562323},
  groups    = {Stereo Camera},
  publisher = {Hindawi Limited},
}

@Book{Zin2016,
  editor    = {Thi Thi Zin and Jerry Chun-Wei Lin and Jeng-Shyang Pan and Pyke Tin and Mitsuhiro Yokota},
  publisher = {Springer International Publishing},
  title     = {Genetic and Evolutionary Computing},
  year      = {2016},
  doi       = {10.1007/978-3-319-23204-1},
}

@Article{,
  journal = {Fisheries Bulletin},
  year    = {2001},
  month   = {01},
  pages   = {38-49},
}

@InProceedings{Akkaynak_2017_CVPR,
author = {Akkaynak, Derya and Treibitz, Tali and Shlesinger, Tom and Loya, Yossi and Tamir, Raz and Iluz, David},
title = {What Is the Space of Attenuation Coefficients in Underwater Computer Vision?},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@misc{StewartArchive,
abstract = {Papers of James Ronald Stewart, diving officer for the Scripps Institution of Oceanography from 1960-1991. During this period, Stewart developed scuba diving training procedures, equipment standards and diving manuals that became a model for scientific diving in the United States and influenced diving practice internationally. The collection includes documentation of diving programs, physiology, accidents, suits, decompression, shark attacks, underwater communication and other subjects related to research diving, in addition to correspondence, teaching materials, photographs, diving logs, safety manuals and other documentation of the history of scientific diving and scuba diving at the Scripps Institution of Oceanography. The collection also includes some files of Stewart's predecessor, Conrad Limbaugh, and correspondence exchanged with Hugh Bradner, Jacquest Yves Cousteau, Robert Livingston, Boyd Walker, Charles Wheelock and others},
author = {Stewart, James R. (James Ronald)},
keywords = {Stewart, James R. (James Ronald), 1927-2017 -- Archives},
language = {eng},
title = {James Stewart Papers},
year = {1943 - 2008},
}

@Article{Ziegler2024,
author = {Ziegler, Shelby L. and Brooks, Rachel O. and Bellquist, Lyall F. and Caselle, Jennifer E. and Morgan, Steven G. and Mulligan, Timothy J. and Ruttenberg, Benjamin I. and Semmens, Brice X. and Starr, Richard M. and Tyburczy, Joe and Wendt, Dean E. and Buchheister, Andre and Jarrin, Jose R. Marin and Pasparakis, Christina and Jorgensen, Salvador J. and Chiu, Jennifer A. and Colby, Jordan and Coscino, Connor L. and Davis, Leon and Castro, Francine de and Elstner, Jack T. and Honeyman, Christopher and Jarvis Mason, Erica T. and Johnston, Erin M. and Small, Sadie L. and Staton, Jay and Waltz, Grant T. and Basnett, Bonnie and Satterthwaite, Erin V. and Killeen, Helen and Dibble, Connor D. and Hamilton, Scott L.},
title = {Collaborative fisheries research reveals reserve size and age determine efficacy across a network of marine protected areas},
journal = {Conservation Letters},
volume = {n/a},
number = {n/a},
pages = {e13000},
keywords = {biomass, California, community-based science, empirical data, fish communities, marine protected areas, productivity, reserve network},
doi = {https://doi.org/10.1111/conl.13000},
url = {https://conbio.onlinelibrary.wiley.com/doi/abs/10.1111/conl.13000},
eprint = {https://conbio.onlinelibrary.wiley.com/doi/pdf/10.1111/conl.13000},
abstract = {Abstract A variety of criteria may influence the efficacy of networks of marine protected areas (MPA) designed to enhance biodiversity conservation and provide fisheries benefits. Meta-analyses have evaluated the influence of MPA attributes on abundance, biomass, and size structure of harvested species, reporting that MPA size, age, depth, and connectivity influence the strength of MPA responses. However, few empirical MPA evaluation studies have used consistent sampling methodology across multiple MPAs and years. Our collaborative fisheries research program systematically sampled 12 no-take or highly protective limited-take MPAs and paired fished reference areas across a network spanning 1100Â km of coastline to evaluate the factors driving MPA efficacy across a large geographic region. We found that increased size and age consistently contributed to increased fish catch, biomass, and positive species responses inside MPAs, while accounting for factors such as latitude, primary productivity, and distance to the nearest MPA. Our study provides a model framework to collaboratively engage diverse stakeholders in fisheries research and provide high-quality data to assess the success of conservation strategies.}
}



@Comment{jabref-meta: VersionDBStructure:1}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Acoustic Camera\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Camera Calibration\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Ecology\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Fish Analysis\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Image Processing\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Laser Rangefinder\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Monocular Depth Camera\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Optics\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:RealSense System\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Stereo Camera\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Underwater Positioning\;0\;1\;0x8a8a8aff\;\;\;;
}

@Comment{jabref-meta: keypatterndefault:[auth][year];}

@Comment{jabref-meta: saveActions:disabled;
all-text-fields[identity]
date[normalize_date]
month[normalize_month]
pages[normalize_page_numbers]
;}

@Comment{jabref-meta: saveOrderConfig:specified;citationkey;false;author;false;title;true;}
